### **问题1：K-最近邻交叉验证（k-fold Cross Validation, 8+8+8=24 Marks）**

#### **第一部分：交叉验证概念与代码实现**

**内容概述:**  
这部分要求你使用 k-fold 交叉验证（k-fold Cross Validation）方法来评估 KNN 回归模型的性能。具体来说，是针对一个从 make_regression 生成的合成数据集，测试一系列不同的 k 值（从1到25），并找出在验证集上表现最好的 k 值。

**参数变动效果 (k 的变化):**  
k 值是 KNN 模型复杂度的关键。

- **小的 k 值 (例如 k=1):** 模型会非常复杂和灵活。它只考虑最近的一个邻居的意见，因此决策边界或回归曲线会非常曲折，紧密地贴合训练数据。这会导致：
    
    - **低偏差（Low Bias）:** 模型能很好地拟合训练数据。
    - **高方差（High Variance）:** 模型对训练数据的噪声和微小变化非常敏感。因此，它在新的、未见过的数据（验证集或测试集）上表现会很差，容易产生**过拟合（Overfitting）**。
        
- **大的 k 值 (例如 k=25):** 模型会变得非常简单和平滑。它会考虑很多邻居的平均结果，从而忽略掉数据中的局部细节和噪声。这会导致：
    - **高偏差（High Bias）:** 模型可能因为过于简单而无法捕捉到数据中真实的、复杂的规律，导致**欠拟合（Underfitting）**。
    - **低方差（Low Variance）:** 模型对数据的微小变化不敏感，在不同训练集上的表现会比较稳定。

**代码实现逻辑:**
1. **数据生成与分割:**
    - make_regression 用于创建一个符合回归任务的合成数据集。
    - train_test_split 将数据分为训练集（80%）和测试集（20%）。测试集在这里暂时不用，主要用于最后的模型评估。
2. **交叉验证循环:**
    - **KFold(n_splits=5, shuffle=True):** 创建一个5折交叉验证的迭代器。这意味着训练集将被分成5个部分（folds）。在每次迭代中，4个部分用作该次迭代的训练数据，剩下的1个部分用作验证数据。shuffle=True 确保在分割前数据被打乱，以避免数据顺序带来的偏差。
    - **外层循环 (for k in k_values)**: 遍历所有要测试的 k 值（从1到25）。
    - **内层循环 (for train_idx, val_idx in kf.split(X_train))**: 这是交叉验证的核心。对于每一个 k 值，它会执行5次训练和验证：
        - kf.split(X_train) 会生成5组训练数据索引（train_idx）和验证数据索引（val_idx）。
        - KNeighborsRegressor(n_neighbors=k): 初始化一个 KNN 回归器，设定邻居数量为当前的 k 值。
        - model.fit(X_train[train_idx], y_train[train_idx]): 在当前折的训练数据上训练模型。
        - mean_squared_error(...): 在当前折的训练数据和验证数据上分别计算均方误差（MSE），并存储起来。
3. **结果计算与可视化:**
    
    - 循环结束后，对于每个 k 值，我们都得到了5个训练MSE和5个验证MSE
    - np.mean(...): 通过计算这5个MSE的平均值，可以得到该 k 值下更稳健的性能评估。
    - **绘图**: 代码绘制了随着 k 值变化的平均训练误差和平均验证误差曲线
        - **x轴**: k 值（模型复杂度）。
        - **y轴**: 均方误差（模型性能）。
    - **寻找最优k**: np.argmin(mean_validation_errors) 找到了使平均验证误差最小的那个点的索引，从而确定了最佳的 k 值。
        

#### **第二部分：结果分析与图表解读**

**图表 (KNN Regression Performance vs. Number of Neighbors (k)) 解读:**  
这个图完美地展示了偏差-方差权衡（Bias-Variance Tradeoff）:

- **蓝色曲线（平均训练误差）**: 当 k 很小时，训练误差非常低（接近于0），因为模型完美地记住了训练数据。随着 k 的增加，模型变得简单，无法完美拟合训练数据，所以训练误差逐渐上升。
    
- **橙色曲线（平均验证误差）**:
    
    - **过拟合区域 (左侧, k 值小)**: 当 k 很小时，验证误差非常高。这是因为模型过于复杂，把训练数据中的噪声也学进去了，导致其泛化到新数据（验证集）上的能力很差。
        
    - **欠拟合区域 (右侧, k 值大)**: 当 k 很大时，验证误差也很高。这是因为模型过于简单，无法捕捉数据中的真实规律。
        
    - **“刚刚好”的区域 (中间)**: 在图中的 k 值约为9的位置，验证误差曲线达到了最低点。这个点就是偏差和方差之间的一个最佳平衡点。这里的模型既不过于复杂（避免了过拟合），也不过于简单（避免了欠拟合），因此在新数据上表现最好。
        

**结论:**  
根据交叉验证的结果，k=9 是最优的选择，因为它在未见过的数据上（由验证集模拟）取得了最低的误差。这个过程清晰地展示了如何通过系统性的实验和评估来选择模型的超参数，从而提高模型的泛化能力。

第三部分
**代码实现逻辑:**

1. **定义搜索空间:**
    
    - param_grid = {'n_neighbors': np.arange(1, 26)}: 创建一个字典，告诉 GridSearchCV 要调整哪个参数（'n_neighbors'）以及要尝试哪些值（1到25）。
        
2. **初始化GridSearchCV:**
    - GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error'):
        - KNeighborsRegressor(): 这是要进行调优的基础模型。
        - param_grid: 指定了要搜索的参数网格。
        - cv=5: 指示使用5折交叉验证。
        - scoring='neg_mean_squared_error': 指定评估性能的指标。这里用的是**负均方误差**，因为 scikit-learn 的习惯是**最大化**一个分数，所以最大化负MSE就等同于**最小化**MSE。
            
3. **执行搜索:**
    
    - grid_search.fit(X_train, y_train): 这是最关键的一步。调用 .fit() 方法后，GridSearchCV 会自动完成以下所有操作：
        
        - 对 param_grid 中的每一个 k 值（从1到25）。
            
        - 执行5折交叉验证。
            
        - 计算每个 k 值在5折上的平均 neg_mean_squared_error。
            
        - 在内部记录下所有结果。
            
4. **获取最佳结果:**
    
    - grid_search.best_params_: 在搜索完成后，这个属性会返回一个字典，其中包含了产生最佳分数的参数组合（例如 {'n_neighbors': 9}）。
        
    - grid_search.best_estimator_: 这个属性返回的是**已经用找到的最佳参数在整个训练集上重新训练过**的模型。这是一个可以直接用于预测的最佳模型。
        
5. **最终评估:**
    
    - 代码最后使用这个 best_estimator_ 在一开始预留的、从未用于训练或验证的**测试集**（test set）上进行预测，并计算最终的测试误差。这个误差是衡量模型最终泛化能力的最公正的指标。
        

**优点:**  
使用 GridSearchCV 的好处是显而易见的：它将繁琐的循环和评估过程封装成几行代码，不仅使代码更简洁，而且减少了出错的可能，是业界进行超参数调优的标准做法。

### **问题4：岭回归 (Ridge Regression, 10+8+8=26 Marks)**

#### **第一部分：数学推导 (Derivation)**

**内容概述:**  
这部分要求从数学上推导出岭回归的解。它要求从带正则化的代价函数（Cost Function）出发，推导出两种求解方式之一：

1. **正规方程（Normal Equation）**: 一个直接求解权重 w 的线性方程组。
    
2. **随机梯度下降（SGD）的权重更新规则**: 一个迭代更新权重 w 的方法。
    

**核心概念与参数效果:**

- **核心概念**: 岭回归在标准的最小二乘法（OLS）的代价函数上，增加了一个惩罚项 λ ||w||² (λ 乘以所有权重平方和)。
    
- **参数 λ (Lambda) 的效果**: λ 是正则化参数，它控制着惩罚的强度。
    
    - **λ = 0**: 惩罚项为0，岭回归退化为普通的最小二乘法线性回归，可能会过拟合。
        
    - **λ > 0**: 惩罚模型中较大的权重。λ 越大，惩罚越强，模型的权重就会被压缩得越小，使得模型更简单，有助于防止过拟合。
        
    - **λ → ∞**: 惩罚变得极其强大，所有权重都将被迫趋近于0，导致模型变为一条水平线，产生欠拟合。
        

**推导逻辑:**

1. **定义代价函数 J(w):**  
    J(w) = 均方误差(MSE) + L2惩罚项  
    用矩阵表示为: J(w) = (Xw - y)ᵀ(Xw - y) + λwᵀw (这里忽略了为简化而使用的 1/2m 等常数，与文档中的推导一致)。
    
2. **计算梯度 ∇J(w):**  
    对代价函数 J(w) 关于权重向量 w 求导。
    
    - MSE部分的导数是 2Xᵀ(Xw - y)。
        
    - L2惩罚项的导数是 2λw。
        
    - 两者相加得到完整的梯度: ∇J(w) = 2Xᵀ(Xw - y) + 2λω。
        
3. **得出两种求解形式:**
    
    - **a) 正规方程 (Normal Equation):**  
        令梯度为0，∇J(w) = 0，然后解出 w:  
        2Xᵀ(Xw - y) + 2λω = 0  
        (XᵀX + λI)w = Xᵀy (其中 I 是单位矩阵)  
        最终解为: w = (XᵀX + λI)⁻¹Xᵀy。这是一个解析解，可以通过矩阵运算一次性求出最优的 w。
        
    - **b) 随机梯度下降 (SGD) 更新规则:**  
        使用梯度来迭代地更新权重：w := w - α * ∇J(w) (其中 α 是学习率)。  
        对于单个样本，梯度为 2(wᵀx - y)x + 2λw。  
        代入更新规则得到: w := w - α * [2(wᵀx - y)x + 2λw]。  
        整理后可得: w := w(1 - 2αλ) - α * 2(wᵀx - y)x。这个形式清晰地展示了L2正则化的“权重衰减（Weight Decay）”效应：在每次更新时，权重 w 自身会先按比例 (1 - 2αλ) 进行缩减，然后再减去常规的误差项。
#### **第二部分：代码实现 (Implementation)**

**内容概述:**  
这部分要求根据第一部分推导出的正规方程（Normal Equation），从零开始实现一个岭回归的类。该类需要包含 fit 和 predict 方法，并且不能使用 scikit-learn 中现成的线性模型。

**代码实现逻辑 (RidgeRegression 类):**

1. **__init__**: 初始化方法，接收正则化参数 alpha (即 λ) 并保存。
    
2. **fit(X, y)**: 训练方法，其核心是实现正规方程 w = (XᵀX + λI)⁻¹Xᵀy。
    
    - 它首先给特征矩阵 X 增加一列全为1的偏置项（intercept term），以便模型能学习截距。
        
    - 然后创建一个单位矩阵 I。非常关键的一步是，它将 I 的第一个元素 I[0, 0] 设置为0。这是因为**我们通常不对偏置项进行正则化惩罚**，因为它只是平移函数，控制其大小没有意义。
        
    - 计算 A = XᵀX + λI。
        
    - 计算 b = Xᵀy。
        
    - 使用 np.linalg.solve(A, b) 来求解线性方程组 Aw = b 得到权重 w。这种方法比直接求逆 np.linalg.inv(A) @ b 在数值上更稳定、更高效。
        
3. **predict(X)**: 预测方法，它拿到新的 X 数据，同样增加偏置列，然后用训练好的权重 self.weights_ 计算预测结果 y = Xw。
    

---

#### **第三部分：实验与分析 (Experiment and Analysis)**

**内容概述:**  
这部分要求设计一个实验来研究正则化参数 λ (alpha) 对模型性能的影响。实验在一个非线性的合成数据集上进行，并使用一个包含5次多项式特征和我们自己实现的岭回归的**流水线（Pipeline）**模型。

选择“5次多项式”和“小训练集（20个样本）”是为了**故意制造一个容易过拟合的场景**，这样正则化的效果才会更加明显。

**参数变动效果 (λ 的变化):**  
参数 λ 从一个极小值 (10⁻¹⁰) 变化到一个较大值 (10⁻¹)。

**代码实现逻辑:**

1. **创建实验环境:**
    
    - 定义一个 data_generator 函数来生成 y = cos(3πx) / (2+x) + 噪声 的数据。
        
    - 设置实验参数，如重复次数 N_REPETITIONS = 10，训练集大小 TRAIN_SIZE = 20 等。
        
    - 使用 np.geomspace 生成一个在对数尺度上均匀分布的 λ 列表。
        
2. **执行实验循环:**
    
    - **外层循环**重复整个实验10次，每次都生成新的训练数据，但使用固定的测试集。这是为了通过求平均来消除单次数据采样的随机性，使结果更可靠。
        
    - **内层循环**遍历所有待测试的 λ 值。
        
    - 在循环内部，创建一个 Pipeline，它先用 PolynomialFeatures(degree=5) 将原始特征转换为多项式特征，然后用我们实现的 RidgeRegression 进行拟合。
        
    - 记录下每个 λ 值对应的训练误差和测试误差。
        
3. **结果分析与可视化:**
    
    - 将10次实验的误差取平均值。
        
    - 绘制一个**双对数坐标图（log-log plot）**，其中X轴是 λ（对数尺度），Y轴是均方误差（对数尺度）。X轴被反转，使得模型复杂度从右到左降低，这是一种常见的可视化习惯。
        
    - 通过 np.argmin(mean_test_error) 找到使平均测试误差最小的那个 λ 值。
        

**图表解读（偏差-方差权衡）:**  
这张图完美地展示了**偏差-方差权衡（Bias-Variance Tradeoff）**：

- **图的右侧 (λ 很小):** 正则化惩罚几乎不起作用。高阶多项式模型可以非常自由地去拟合小训练集中的每一个点，包括噪声。这导致：
    
    - **训练误差极低**。
        
    - **测试误差非常高**。
        
    - 这就是**过拟合（Overfitting）**区域，模型具有高方差。
        
- **图的左侧 (λ 很大):** 正则化惩罚占主导地位，迫使模型的权重都非常小。模型变得极其简单，近乎一条直线。这导致：
    
    - **训练误差和测试误差都很高**。
        
    - 这就是**欠拟合（Underfitting）**区域，模型具有高偏差。
        
- **图中部 (最佳区域):** 在图的中间，测试误差曲线达到了一个最低点。这个点对应的 λ 值在偏差和方差之间取得了最佳平衡。模型既足够复杂以捕捉数据中的真实趋势，又通过正则化受到了足够的约束，避免了学习噪声。这就是“恰到好处”的模型。
### **逻辑回归 vs. 贝叶斯分类器**

这份文件的核心是比较两种不同类型的概率分类模型——**判别模型（Discriminative Model）**的代表**逻辑回归**，和**生成模型（Generative Model）**的代表**贝叶斯分类器**——在不同训练数据量下的性能表现。

#### **第一部分：初始模型比较**

**内容概述:**  
加载乳腺癌数据集，将其按80/20的比例分割为训练集和测试集。然后训练并评估四种模型：

1. **逻辑回归 (Logistic Regression)**
    
2. **朴素贝叶斯 (Naive Bayes)**: 一种简单的生成模型，假设特征之间相互独立。
    
3. **贝叶斯（共享协方差）(Bayes (Shared Cov))**: 一种二次判别分析（QDA）的变体，假设所有类别的协方差矩阵是相同的。
    
4. **贝叶斯（非共享协方差）(Bayes (Non-Shared Cov))**: 标准的二次判别分析，每个类别都有自己独立的协方差矩阵。
    

**代码实现逻辑:**  
直接调用 scikit-learn 库中的相应模块。LogisticRegression 是判别模型，而 GaussianNB 和 QuadraticDiscriminantAnalysis 属于生成模型。代码逻辑是标准的初始化、训练 (.fit) 和评估 (accuracy_score) 流程。

#### **第二、三部分：学习曲线实验与绘图**

**内容概述:**  
设计一个实验来观察当训练集的大小从很小（N=5）增加到较大（N=500）时，各个模型的性能（准确率）如何变化。为了结果的稳定性，每个训练集大小N的实验都重复10次。最终将平均性能绘制成**学习曲线（Learning Curves）**。

**代码实现逻辑:**

1. **固定测试集:** 首先分割出一个固定的测试集，该测试集在整个实验过程中保持不变，以确保所有模型的最终评估都是在同一基准下进行的。
    
2. **双重循环:**
    
    - 外层循环遍历不同的训练集大小 n。
        
    - 内层循环重复实验10次。在每次重复中，从完整数据集中随机抽取 n 个样本作为当前的训练集。
        
    - 在循环体中，所有四种模型都在这个大小为 n 的训练集上进行训练，然后在该训练集和固定的测试集上分别评估其准确率。
        
3. **结果聚合与绘图:**
    
    - 对于每个训练集大小 n，将10次重复实验的训练准确率和测试准确率分别取平均值。
        
    - 使用 matplotlib 绘制学习曲线，X轴是训练集大小，Y轴是准确率。训练曲线用虚线，测试曲线用实线。
        

#### **第四部分：分析与回答**

这部分是整个问题的精华，通过分析学习曲线来回答三个关键问题。

**a. 增加训练数据有什么效果？**

- **回答:** 随着训练数据的增加，所有模型的**测试准确率**都呈现出**上升然后趋于平稳**的趋势。同时，**训练准确率和测试准确率之间的差距逐渐缩小**。
    
- **原因:** 更多的数据让模型能够学习到更普适的规律，减少了对训练数据中噪声和特例的依赖，从而**降低了过拟合**，提高了泛化能力。
    

**b. 在训练集很小和很大时，哪个分类器最好？**

- **回答:**
    
    - **训练集很小 (N < 50) 时: 朴素贝叶斯 (Naive Bayes) 表现最好。**
        
    - **训练集很大 (N > 200) 时: 逻辑回归 (Logistic Regression) 表现最好。**
        
- **原因解释见下一题。**
    

**c. 解释你的观察。**

- **核心区别：生成模型 vs. 判别模型**
    
    - **生成模型** (如贝叶斯分类器) 试图学习数据的联合概率分布 P(x, y)，即数据是如何生成的。它拥有关于数据结构的“先验知识”或假设。
        
    - **判别模型** (如逻辑回归) 则直接学习决策边界，即给定数据 x，它属于类别 y 的概率 P(y|x)。
        
- **解释:**
    
    1. **朴素贝叶斯 (小数据集优胜者):** 它有一个非常强的**特征独立性假设**。这个假设虽然在现实中往往不成立，但极大地减少了模型需要学习的参数数量（它不需要计算特征之间的协方差）。在数据量很少时，这种**高偏差、低方差**的特性使它不容易过拟合，表现反而最稳健。
        
    2. **贝叶斯（非共享协方差）(小数据集表现差):** 这个模型最复杂，需要为每个类别估计一个完整的协方差矩阵，参数非常多。在数据少时，这些参数的估计会非常不稳定（高方差），导致模型性能很差。
        
    3. **逻辑回归 (大数据集优胜者):** 作为一个判别模型，它不关心数据是如何生成的，只专注于找到最佳的决策边界。当数据量充足时，它不再受限于生成模型那些可能不准确的先验假设，可以直接、灵活地学习到更优的分类边界，因此性能最终会超过生成模型。
        
    4. **总结:** 模型的性能是其**内在假设（偏差）**和**数据量**之间相互作用的结果。简单的模型（如朴素贝叶斯）在数据少时占优，而更灵活的模型（如逻辑回归）在数据充足时能发挥更大潜力。
###  Question 1: k-fold Cross Validation (8+8+8=24 Marks)**

#### **Part 1: Cross-Validation Concept and Code Implementation**

**Content Overview:**  
This part requires you to use the k-fold cross-validation method to evaluate the performance of a KNN regression model. Specifically, you will test a range of different 'k' values (from 1 to 25) on a synthetic dataset generated by make_regression and identify the 'k' value that performs best on the validation sets.

**Effect of Parameter Variation (the change in k):**  
The value of k is the key to the KNN model's complexity.

- **Small k (e.g., k=1):** The model becomes very complex and flexible. It only considers the single nearest neighbor, causing the decision boundary or regression curve to be highly erratic and closely follow the training data. This leads to:
    
    - **Low Bias:** The model fits the training data very well.
    - **High Variance:** The model is highly sensitive to noise and minor fluctuations in the training data.As a result, it performs poorly on new, unseen data (like a validation or test set), which is known as **Overfitting**.
        
- **Large k (e.g., k=25):** The model becomes very simple and smooth. It averages the results from many neighbors, thereby smoothing out local details and noise. This leads to:
    
    - **High Bias:** The model might be too simple to capture the true, complex patterns in the data, resulting in **Underfitting**
        
    - **Low Variance:** The model is less sensitive to small changes in the data and will perform more consistently across different training sets.
**Code Implementation Logic:**

1. **Data Generation and Splitting:**
    
    - make_regression is used to create a synthetic dataset suitable for a regression task.
        
    - train_test_split divides the data into a training set (80%) and a test set (20%). The test set is held out for the final model evaluation and is not used during cross-validation.
        
2. **Cross-Validation Loop:**
    
    - **KFold(n_splits=5, shuffle=True):** This creates a 5-fold cross-validation iterator.It means the training set will be divided into 5 equal parts (folds). In each iteration, 4 folds are used for training, and the remaining 1 fold is used for validation. shuffle=True ensures the data is randomized before splitting to prevent any bias from the data's original order.
    - **Outer Loop (for k in k_values):** This loop iterates through all the 'k' values you want to test (1 through 25).
    - **Inner Loop (for train_idx, val_idx in kf.split(X_train)):** This is the core of cross-validation. For each k, it performs training and validation 5 times:
        - kf.split(X_train) generates 5 sets of indices for the training data (train_idx) and validation data (val_idx).
        - KNeighborsRegressor(n_neighbors=k): Initializes a KNN regressor, setting the number of neighbors to the current k.
        - model.fit(X_train[train_idx], y_train[train_idx]): Trains the model on the current fold's training data.
        - mean_squared_error(...): Calculates the Mean Squared Error (MSE) on both the training and validation data for the current fold and stores the results.
            
3. **Result Calculation and Visualization:**
    - After the loops complete, for each k value, we have 5 training MSEs and 5 validation MSEs.
    - np.mean(...): By calculating the average of these 5 MSEs, we get a more robust estimate of the model's performance for that k.
    - **Plotting**: The code generates a plot showing the average training and validation errors as a function of k.
        - **x-axis**: The k value (Model Complexity).
        - **y-axis**: Mean Squared Error (Model Performance).
    - **Finding Optimal k**: np.argmin(mean_validation_errors) finds the index of the minimum value in the average validation errors, which corresponds to the best k value.
#### **Part 2: Results Analysis and Plot Interpretation**

**Interpreting the Plot (KNN Regression Performance vs. Number of Neighbors (k)):**  
This plot perfectly illustrates the Bias-Variance Tradeoff:

- **Blue Curve (Mean Training Error):** When k is small, the training error is very low (near zero) because the model has "memorized" the training data. As k increases, the model becomes simpler and cannot fit the training data as perfectly, so the training error gradually increases.
- **Orange Curve (Mean Validation Error):**
    - **Overfitting Region (Left side, small k):** When k is small, the validation error is very high. This is because the overly complex model has learned the noise in the training data and fails to generalize to new data (the validation set)
    - **Underfitting Region (Right side, large k):** When k is large, the validation error is also high. This is because the model is too simple and cannot capture the underlying pattern in the data
        
    - **"Just Right" Region (Middle):** Around k=9, the validation error curve hits its lowest point. This point represents the best balance between bias and variance The model here is complex enough to capture the true pattern but not so complex that it overfits the noise.

**Conclusion:**  
Based on the cross-validation results, k=9 is the optimal choice because it achieves the lowest error on unseen data (as simulated by the validation sets). This process clearly demonstrates how to systematically experiment and evaluate to select a model's hyperparameters, thereby improving its ability to generalize.
1. **Define the Search Space:**
    - param_grid = {'n_neighbors': np.arange(1, 26)}: A dictionary is created to tell GridSearchCV which parameter to tune ('n_neighbors') and which values to try (1 to 25).
2. **Initialize GridSearchCV:**
    - GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error'):
        - KNeighborsRegressor(): The base model to be tuned.
        - param_grid: The parameter grid to search over.
        - cv=5: Specifies that 5-fold cross-validation should be used.
        - scoring='neg_mean_squared_error': The metric for performance evaluation. **Negative Mean Squared Error** is used because scikit-learn's convention is to **maximize** a score. Therefore, maximizing the negative MSE is equivalent to **minimizing** the MSE.
3. **Execute the Search:**
    - grid_search.fit(X_train, y_train): This is the most crucial step. When .fit() is called, GridSearchCV automatically performs all of the following:
        - For each k value in param_grid (from 1 to 25).
        - It runs a 5-fold cross-validation.
        - It calculates the average neg_mean_squared_error across the 5 folds for that k.
        - It internally stores all the results.
4. **Retrieve the Best Results:**
    - grid_search.best_params_: After the search is complete, this attribute returns a dictionary containing the parameter combination that yielded the best score (e.g., {'n_neighbors': 9}).
    - grid_search.best_estimator_: This attribute returns the model that has **already been re-trained on the entire training set using the best parameters found**. This is the optimal model, ready to be used for prediction.
5. **Final Evaluation:**
    - Finally, the code uses this best_estimator_ to make predictions on the **test set**, which was held out from the very beginning and never used in training or validation. The resulting test error is the most unbiased measure of the model's final generalization performance.

**Advantages:**  
The benefits of using GridSearchCV are clear: it encapsulates the tedious process of loops and evaluations into just a few lines of code. This not only makes the code cleaner but also reduces the chance of manual errors, making it the standard industry practice for hyperparameter tuning.
###  **问题4：岭回归 Ridge Regression**

This document focuses on understanding and implementing **Ridge Regression**, an improved version of linear regression that uses **L2 Regularization** to prevent overfitting.

#### **Part 1: Mathematical Derivation**

**Content Overview:**  
This section requires the mathematical derivation of the solution for Ridge Regression. Starting from the regularized cost function, the goal is to derive one of two solution forms:

1. **The Normal Equation**: A direct, analytical solution for the weights w.
    
2. **The Stochastic Gradient Descent (SGD) update rule**: An iterative method for updating the weights w.
    

**The Role of Ridge Regression and L2 Regularization:**  
The primary purpose of Ridge Regression is to address the problem of **overfitting** in standard linear regression models. Overfitting often occurs when the model is too complex for the amount of training data available (e.g., when using high-degree polynomial features or when there are many input features).

L2 regularization achieves this by adding a **penalty term (λ ||w||²)** to the model's cost function. This penalty discourages the model from learning overly large weights.

- **How it works:** By penalizing the squared magnitude of the weights, it forces the model to find a balance between fitting the data well (minimizing the error) and keeping the weights small (minimizing the penalty).
    
- **Effect:** This results in a "simpler" model that is less sensitive to the noise in the training data and is therefore more likely to **generalize** well to new, unseen data. The strength of this penalty is controlled by the hyperparameter λ (lambda).
    

**Derivation Logic:**

1. **Define the Cost Function J(w):**  
    J(w) = Mean Squared Error (MSE) + L2 Penalty Term  
    In matrix form: J(w) = (Xw - y)ᵀ(Xw - y) + λwᵀw.
    
2. **Calculate the Gradient ∇J(w):**  
    Take the derivative of the cost function with respect to the weight vector w.
    
    - The derivative of the MSE term is 2Xᵀ(Xw - y).
        
    - The derivative of the L2 penalty term is 2λw.
        
    - The full gradient is: ∇J(w) = 2Xᵀ(Xw - y) + 2λω.
        
3. **Derive the Two Solution Forms:**
    
    - **a) Normal Equation:**  
        Set the gradient to zero, ∇J(w) = 0, and solve for w:  
        2Xᵀ(Xw - y) + 2λω = 0  
        (XᵀX + λI)w = Xᵀy (where I is the identity matrix)  
        The final analytical solution is: w = (XᵀX + λI)⁻¹Xᵀy.
        
    - **b) Stochastic Gradient Descent (SGD) Update Rule:**  
        Use the gradient to iteratively update the weights: w := w - α * ∇J(w) (where α is the learning rate).  
        For a single sample, the update rule becomes: w := w - α * [2(wᵀx - y)x + 2λw].  
        Rearranging gives: w := w(1 - 2αλ) - α * 2(wᵀx - y)x. This form clearly shows the "**weight decay**" effect of L2 regularization: in each step, the weights w are first shrunk by a factor of (1 - 2αλ) before the standard error update is applied.
        

---

#### **Part 2: Code Implementation**

**Content Overview:**  
This part requires implementing a Ridge Regression class from scratch based on the derived Normal Equation. The class needs fit and predict methods and must not use any pre-built linear models from scikit-learn.

**Code Implementation Logic (RidgeRegression Class):**  
The implementation correctly follows the Normal Equation w = (XᵀX + λI)⁻¹Xᵀy. A key detail is setting I[0, 0] to 0, which correctly **exempts the bias/intercept term from regularization**, as penalizing it is generally not necessary or beneficial. The use of np.linalg.solve(A, b) instead of direct matrix inversion is a best practice for numerical stability and efficiency.

---

#### **Part 3: Experiment and Analysis**

**Content Overview:**  
This section designs an experiment to study the effect of the regularization parameter λ (alpha) on model performance. The experiment is conducted on a non-linear synthetic dataset, using a **Pipeline** that combines 5th-degree polynomial features with the custom-built RidgeRegression.

The choice of a high-degree polynomial (degree 5) and a small training set (20 samples) is intentional to **create a scenario that is highly prone to overfitting**, thus making the effects of regularization clearly visible.

**Interpreting the Plot (Bias-Variance Tradeoff):**  
The log-log plot perfectly demonstrates the **Bias-Variance Tradeoff**:

- **Right Side of the Plot (λ is very small):** The regularization penalty is negligible. The complex polynomial model freely fits the training data, including its noise. This results in:
    
    - Extremely low training error.
        
    - Very high testing error.
        
    - This is the **Overfitting** region, where the model has high variance.
        
- **Left Side of the Plot (λ is large):** The regularization penalty dominates, forcing all model weights toward zero. The model becomes overly simple. This results in:
    
    - High training error and high testing error.
        
    - This is the **Underfitting** region, where the model has high bias.
        
- **"Just Right" Region (in the middle):** The test error curve reaches a minimum. The corresponding λ value strikes the optimal balance between bias and variance. The model is complex enough to capture the true data trend but is sufficiently constrained by regularization to avoid fitting the noise. This is the ideal model.
### **Logistic Regression vs. Bayes Classifier**

This document's core objective is to compare the performance of two different types of probabilistic classification models—**Logistic Regression**, a representative **Discriminative Model**, and the **Bayes Classifier**, a representative **Generative Model**—across varying amounts of training data.

#### **Part 1: Initial Model Comparison**

**Content Overview:**  
Load the breast cancer dataset, split it into an 80/20 training/test set, and then train and evaluate four models:

1. **Logistic Regression**
    
2. **Naive Bayes**: A simple generative model that assumes features are mutually independent.
    
3. **Bayes (Shared Covariance)**: A variant of Quadratic Discriminant Analysis (QDA) that assumes the covariance matrix is the same for all classes.
    
4. **Bayes (Non-Shared Covariance)**: Standard QDA, where each class has its own independent covariance matrix.
    

**Code Implementation Logic:**  
This involves direct calls to the respective scikit-learn modules. LogisticRegression is the discriminative model, while GaussianNB and QuadraticDiscriminantAnalysis are generative models. The code follows a standard initialize, train (.fit), and evaluate (accuracy_score) workflow.

#### **Parts 2 & 3: Learning Curves Experiment and Plotting**

**Content Overview:**  
Design an experiment to observe how the performance (accuracy) of each model changes as the training set size increases from very small (N=5) to larger (N=500). To ensure stable results, the experiment for each training size N is repeated 10 times. The average performance is then plotted as **Learning Curves**.

**Code Implementation Logic:**

1. **Fixed Test Set:** A fixed test set is first partitioned and kept constant throughout the experiment. This ensures that all models are ultimately evaluated against the same benchmark.
    
2. **Nested Loops:**
    
    - The outer loop iterates through different training set sizes n.
        
    - The inner loop repeats the experiment 10 times. In each repetition, n samples are randomly drawn from the full dataset to serve as the current training set.
        
    - Inside the loops, all four models are trained on this training set of size n and evaluated on both that same training set and the fixed test set.
        
3. **Result Aggregation and Plotting:**
    
    - For each training size n, the training and test accuracies from the 10 repetitions are averaged.
        
    - Matplotlib is used to plot the learning curves with training set size on the x-axis and accuracy on the y-axis. Training curves are dashed, and test curves are solid.
        

#### **Part 4: Analysis and Answering Questions**

This is the most critical part, analyzing the learning curves to answer three key questions.

**a. What happens when you increase the training data?**

- **Answer:** As the training data increases, the **test accuracy** of all models tends to **rise and then plateau**. Simultaneously, the **gap between the training accuracy and test accuracy narrows**.
    
- **Reason:** More data allows the model to learn more generalizable patterns, reducing its reliance on noise and idiosyncrasies in the training set. This **reduces overfitting** and improves generalization ability.
    

**b. Which classifier is best for small and large training sets?**

- **Answer:**
    
    - **For small training sets (N < 50): Naive Bayes performs best.**
        
    - **For large training sets (N > 200): Logistic Regression performs best.**
        
- **The justification is provided in the next question.**
    

**c. Justify your observations.**

- **Core Difference: Generative vs. Discriminative Models**
    
    - **Generative Models** (like Bayes classifiers) try to learn the joint probability distribution P(x, y)—how the data is generated. They have "prior knowledge" or assumptions about the data's structure.
        
    - **Discriminative Models** (like Logistic Regression) directly learn the decision boundary or the conditional probability P(y|x).
        
- **Explanation:**
    
    1. **Naive Bayes (Winner on Small Datasets):** It has a very strong **feature independence assumption**. While often incorrect in reality, this assumption drastically reduces the number of parameters the model needs to learn (it doesn't need to compute a covariance matrix between features). With little data, this **high-bias, low-variance** characteristic makes it less prone to overfitting and thus more robust.
        
    2. **Bayes (Non-Shared Covariance) (Loser on Small Datasets):** This is the most complex model, needing to estimate a full covariance matrix for each class, which involves many parameters. With little data, the estimation of these parameters is highly unstable (high variance), leading to poor performance.
        
    3. **Logistic Regression (Winner on Large Datasets):** As a discriminative model, it doesn't care how the data was generated; it focuses solely on finding the best decision boundary. When given enough data, it is not constrained by the potentially incorrect prior assumptions of generative models and can directly learn a more optimal classification boundary, eventually outperforming them.
        
    4. **Summary:** A model's performance is an interplay between its **inherent assumptions (bias)** and the **amount of data**. Simple models with strong assumptions (like Naive Bayes) excel when data is scarce, while more flexible models (like Logistic Regression) can reach their full potential when data is abundant.