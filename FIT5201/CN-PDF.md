
---
# 2
### (软) EM 算法在文档聚类中的推导

以下是用于文档聚类的（软）EM 算法的期望（Expectation）和最大化（Maximization）步骤的推导，包括模型参数及其更新表达式。

#### **模型参数**

在文档聚类的背景下，我们的目标是学习以下参数：
*   **混合系数（聚类先验）$\phi$**：这代表了文档属于特定聚类的先验概率。对于 K 个聚类，我们有一个向量 $\phi = (\phi_1, \phi_2, ..., \phi_K)$，其中 $\phi_k \geq 0$ 且 $\sum_{k=1}^{K} \phi_k = 1$。
*   **每个聚类的词概率 $\mu$**：这是一组参数 $\mu = (\mu_1, \mu_2, ..., \mu_K)$，其中每个 $\mu_k$ 是一个向量，表示词汇表中单词在聚类 *k* 中的概率分布。 因此，$\mu_k = (\mu_{k,1}, \mu_{k,2}, ..., \mu_{k, |A|})$，其中 *|A|* 是词汇表的大小，$\mu_{k,w} \geq 0$，并且 $\sum_{w \in A} \mu_{k,w} = 1$。

#### **期望（E）步骤**

E 步骤计算每个聚类 *k* 对每个文档 *d* 的后验概率或“责任”。这告诉我们，基于当前的参数估计，一个给定的文档属于每个聚类的可能性有多大。

责任 $\gamma(z_{nk})$，即后验概率 $P(z_{nk}=1 | d_n, \theta^{old})$，计算如下：

$\gamma(z_{nk}) = \frac{\phi_k \prod_{w \in d_n} (\mu_{k,w})^{c(w, d_n)}}{\sum_{j=1}^{K} \phi_j \prod_{w \in d_n} (\mu_{j,w})^{c(w, d_n)}}$

其中：
*   $\gamma(z_{nk})$ 是聚类 *k* 对文档 *n* 的责任。
*   $c(w, d_n)$ 是单词 *w* 在文档 $d_n$ 中的计数。

该步骤实质上是计算潜在变量的期望值，在这种情况下，潜在变量是聚类分配。

#### **最大化（M）步骤**

M 步骤更新模型参数（$\phi$ 和 $\mu$），以在给定 E 步骤中计算的责任的情况下，最大化观测数据的期望对数似然。

更新后的参数计算如下：

**混合系数 $\phi_k$ 的更新：**

每个聚类 *k* 的新混合系数是该聚类在所有文档上的平均责任。

$\phi_k^{new} = \frac{\sum_{n=1}^{N} \gamma(z_{nk})}{N}$

其中 *N* 是文档总数。

**每个聚类的词概率 $\mu_{k,w}$ 的更新：**

聚类 *k* 中单词 *w* 的新概率是该单词在所有文档中计数的加权平均值，其中权重是该聚类对该文档的责任。

$\mu_{k,w}^{new} = \frac{\sum_{n=1}^{N} \gamma(z_{nk}) c(w, d_n)}{\sum_{v=1}^{|A|} \sum_{n=1}^{N} \gamma(z_{nk}) c(v, d_n)}$

此步骤根据 E 步骤的“完整”数据找到参数的最大似然估计。

EM 算法在 E 步骤和 M 步骤之间交替进行，直到参数收敛。


# 3
**任务总结**

在此步骤中，我们成功加载了 Task2A.txt 文件中的原始文本文档。

为了将这些文本数据转换为后续EM聚类算法可以使用的数值格式，我们采用了 scikit-learn 库中的 CountVectorizer 工具。该工具自动化地执行了以下关键的预处理操作：

1. **文本小写化**：统一文本格式。
    
2. **分词**：将句子切分为单词。
    
3. **停用词移除**：删除了如 "a", "the", "in" 等常见但信息量低的词语。
    
4. **过滤**：移除了所有标点符号和数字。
    

最终的输出是一个名为 X 的**文档-词频矩阵**。该矩阵的维度是 (N, |A|)，其中 N 是文档的总数，|A| 是从数据集中提取出的独立单词（词汇表）的总数。这个矩阵 X 已经准备就绪，可以作为第四部分EM算法的输入。

# 4
在这一部分中，我们设定聚类数量 **K=4**，并对预处理后的数据执行了硬聚类和软聚类。

为了实现这一点，我们首先调整了 DocumentClusterEM 类，使其能够支持两种方法：

- **软聚类 (soft-EM)**：这是标准的EM算法，其 E 步骤为每个文档计算一个关于所有聚类的概率分布（责任）。一个文档可以部分地属于多个聚类。
    
- **硬聚类 (hard-EM)**：这是一个类似于 K-Means 算法的变体。在 E 步骤中，每个文档被唯一地分配给最可能的那一个聚类。其责任矩阵是二进制的（one-hot 编码）。
    

我们在文档-词频矩阵 X 上运行了这两种模型。结果是两个数组，soft_cluster_labels 和 hard_cluster_labels，它们分别包含了数据集中每个文档的最终聚类分配（一个从0到3的整数）。这两个标签数组是本任务的主要输出，并已准备好用于第六部分所要求的分析和可视化。

# 5
**图表比较**

以上两张图分别可视化了 Soft-EM 和 Hard-EM 算法的聚类结果，它们是将高维数据投影到其前两个主成分上得到的。通过目视检查，两种方法产生的聚类分配结果**极其相似，甚至可以说是完全相同**。代表四个聚类的颜色在两张图中的分布方式完全一致，这表明两种算法收敛到了对文档相同的最终划分。

**相似性解释**

Soft EM 和 Hard EM 的根本区别在于 E 步骤：

- **Soft EM** 计算责任（responsibilities），即一个文档属于每个聚类的概率。一个文档可以同时拥有多个聚类的部分成员资格（例如，70% 属于聚类 A，30% 属于聚类 B）。最终的标签是通过取具有最高概率的聚类（argmax）来确定的。
    
- **Hard EM** 执行“赢家通吃”的分配。它计算出哪个聚类对一个文档来说最可能，然后将其 100% 分配给该聚类，并将对所有其他聚类的责任设置为零。这在概念上与 K-Means 中的分配步骤相似。
    

两种方法都得出了相同的结果，这一事实强烈表明，这个特定数据集中的**聚类是区分得非常好的（well-separated）**。对于大多数文档来说，属于某个聚类的概率可能非常高（例如，> 99%），而属于其他聚类的概率则可以忽略不计。在这种情况下，“软”分配实际上已经接近于“硬”分配。因此，在每一步强制进行硬分配（Hard EM）与计算软概率然后在最后取最大值（Soft EM）最终都导向了相同的稳定解。

如果聚类之间存在大量重叠，我们预计会看到差异。位于两个聚类边界上的文档可能会被这两种方法分配到不同的最终聚类中，因为 Soft EM 的细微概率信息可能会以不同于迭代硬分配的方式影响平衡。在我们的图表中没有出现这种差异，这为数据中清晰明确的聚类结构提供了有力的证据。

# 1

这些图表显示了训练集和测试集中数据点的空间分布。每个点都根据其二元类别标签（类别0或类别1）进行了着色。通过目视检查，可以立即发现数据是**非线性可分**的。两个类别形成了独特的同心环或“甜甜圈”形状，这将对像感知机这样的简单线性分类器构成挑战。这个可视化对于理解我们将在问题后续部分中获得的结果至关重要。

# 2
在此任务中，我们使用学习率（η）分别为 0.1 和 1.0 训练了两个感知机模型。在训练数据上训练后，我们在测试集上评估了它们的性能。

**结果:**

- 学习率为 **η = 0.1** 的模型取得了 **48.80%** 的测试误差。
    
- 学习率为 **η = 1.0** 的模型取得了 **48.80%** 的测试误差。
    

在这种情况下，两个模型的表现同样糟糕。我们选择 η=1.0 的模型进行可视化。

**决策边界分析:**  
该图清晰地展示了感知机模型的根本局限性。作为一个**线性分类器**，它的决策边界永远是一条直线。图中显示了这条直线穿过数据。

然而，正如我们在第一部分中观察到的，数据是**非线性可分**的，两个类别形成了相互交错的弯曲带状。一条直线在几何上无法有效地分离这两个类别。无论这条线如何放置，它都不可避免地会错误分类两个类别的大部分数据。这解释了为什么测试误差会高达近 50%，对于一个平衡的数据集来说，这只比随机猜测好一点点。学习率没有产生显著影响，因为模型的核心假设（线性）与数据的结构从根本上不匹配。

# 3
在此任务中，我们从线性的感知机转向了能够学习非线性决策边界的**3层神经网络（NN）**。我们进行了一次网格搜索，以找到最优的隐藏单元数（K）和学习率（η）。

**过程与结果：**

1. 我们训练了多个神经网络模型，系统地改变了 K（从5到40）和 η（在0.01和0.001之间）。
    
2. 最佳性能是在 **K=30 和 η=0.01** 时取得的，达到了 **99.20%** 的测试准确率（测试误差仅为0.80%）。这与感知机50%的误差相比是一个巨大的进步。
    
3. “K与准确率”的关系图显示了一个清晰的趋势：随着隐藏单元数 K 的增加，模型的准确率通常会提高。这是因为更多的神经元赋予了网络更大的能力来逼近数据所需的复杂曲线边界。性能在 K=30 左右开始趋于平稳，这表明在此之后增加更多神经元所带来的收益递减。
    

**决策边界分析：**  
最终的图生动地展示了神经网络的强大能力。与感知机的直线不同，神经网络学习到了一个**复杂的、非线性的决策边界**。这条边界优雅地弯曲，以分离两个相互缠绕的类别，与数据的真实潜在结构非常吻合。这种创建灵活的、由数据驱动的边界的能力，正是神经网络在简单线性模型失败的任务中表现出色的原因。

# 4
感知机和3层神经网络之间巨大的性能差异，直接源于它们根本上不同的**模型假设**和**模型表达能力**，这一点在我们生成的两张决策边界图中得到了清晰的可视化。

**1. 感知机：一个线性模型**

- **模型假设**：感知机是一个线性分类器。它的核心假设是数据是**线性可分**的，即一条直线（或在高维空间中的一个超平面）就足以将不同类别分开。
    
- **图表分析（来自第二题）**：感知机的决策边界图完美地展示了这一假设。图中显示了一条穿过数据空间的、笔直的决策边界。模型的整个学习过程都致力于为这条直线找到“最佳”的可能位置。
    
- **失败原因**：正如我们在初始数据可视化中观察到的，Task2B 数据集本质上是**非线性**的。两个类别形成了相互缠绕的弯曲带状。将一个线性的边界强加于这个非线性的问题上，是一种根本性的失配。无论这条直线画在哪里，它都不可避免地会错误分类两个类别的大量数据点，从而导致了约50%的错误率，这与随机猜测无异。
    

**2. 3层神经网络：一个非线性模型**

- **模型能力**：3层神经网络是一个**非线性模型**。它不假设数据是线性可分的。其关键在于它的**隐藏层**以及**非线性激活函数**（如ReLU）的结合。这个隐藏层扮演了一个自动特征工程引擎的角色。它学习将原始的输入特征转换为一个全新的、更高层次的表示。在这个新的、转换后的空间里，数据变得线性可分了。最后的输出层则有效地在这个新的、更丰富的特征空间中学习一个线性分离器。
    
- **图表分析（来自第三题）**：神经网络的决策边界图优美地展示了这种能力。它不再是一条僵硬的直线，而是学习到了一个**复杂的、弯曲的、灵活的边界**。这个边界优雅地在两个类别之间穿梭，完美地捕捉了它们之间的非线性关系。
    
- **成功原因**：神经网络之所以在感知机失败的地方取得了成功，是因为它具有高得多的**模型表达能力 (Representational Capacity)**。它不假设一个简单的解；相反，它利用其隐藏层来学习解决问题所需的特定的复杂形状。这种适应性使其能够达到超过99%的近乎完美的准确率。
    

**结论**

总而言之，对这两张图的比较揭示了性能差距的核心原因：

> **感知机的失败，是因为其僵化的线性假设被数据的非线性本质所违背。而3层神经网络的成功，则是因为其架构本身就是为学习和建模复杂的非线性关系而设计的，从而创建了一个能真正拟合数据内在结构的决策边界。**

# 1
在第三部分的这个初始步骤中，我们成功加载了自监督学习任务所需的三个数据集。

- Task2C_labeled.csv: 包含一个较小的数据集，其中提供了特征和类别标签。它将被用来训练最终的监督分类器。该数据已加载到 labeled_df DataFrame中。
    
- Task2C_unlabeled.csv: 包含一个更大的数据集，只有特征，没有类别标签。它将与有标签数据合并，共同用于训练我们的自编码器。该数据已加载到 unlabeled_df DataFrame中。
    
- Task2C_test.csv: 这是我们的保留集，包含模型在训练期间不会看到的特征和标签。它将用于对我们训练好的分类器进行最终评估。该数据已加载到 test_df DataFrame中。
    

所有数据都已使用 pandas 加载，并设置 header=None，因为文件似乎不包含标题行。数据现已准备就绪，可以进行后续训练自编码器和分类器的步骤。

# 2
这一题是第二题的后续和验证。在第二题中，我们训练了多个不同隐藏层大小的自编码器。第三题要求我们**评估这些自编码器的性能**，并解释我们观察到的现象。

具体任务如下：

1. **计算重建误差 (Reconstruction Error)**：对于每一个训练好的自编码器（即，隐藏层神经元数量分别为20, 60, 100, ..., 220的那些模型），计算它的重建误差。
    
    - **如何计算？** 将训练自编码器用的全部数据 (X_autoencoder_train) 输入到模型中，得到重建后的数据。然后，计算原始数据和重建数据之间的**平均欧几里得距离**。
        
2. **绘制误差曲线**：创建一个图表，其中：
    
    - **X轴** 是隐藏层的神经元数量（20, 60, 100, ...）。
        
    - **Y轴** 是对应的重建误差。
        
3. **解释结果**：根据您绘制的图表，解释隐藏层大小如何影响自编码器的重建能力。

# 3
**观察到的现象：**  
图表中清晰可见的趋势是，**随着隐藏层中神经元数量的增加，重建误差随之减小。** 仅有20个神经元的模型误差最高，而拥有220个神经元的模型误差最低。

**原因解释：**  
这个结果是符合预期的，它直接与自编码器的**信息瓶颈**有关。一个**更小的隐藏层**会造成非常紧凑的瓶颈，强制进行高强度压缩并导致信息丢失，从而产生更高的重建误差。而一个**更大的隐藏层**则提供了一个更宽的瓶颈，允许模型保留更多信息，从而实现更精确的重建和更低的误差。

# 4 
在这一步中，我们已经建立了我们的**性能基准**。我们训练了一系列标准的3层神经网络分类器，每个分类器的单一隐藏层都具有不同数量的神经元。

至关重要的是，这些模型**仅在那个小型的、原始的有标签数据集上**（X_labeled）进行了训练。我们在保留的测试集（X_test）上评估了每个模型，并记录了其分类误差。

最终得到的列表 baseline_test_errors 包含了这些标准分类器的性能指标。这些数据将作为第六部分中关键的比较点，届时我们会将它与增强后网络的性能一同绘制，以判断由自编码器学习到的特征是否带来了切实的益处。

我们可以看到，仅使用少量有标签数据训练的标准神经网络，其性能相当不稳定且不理想。最好的模型（20个神经元）的测试误差也高达 **36.40%**，而其他模型的误差甚至更高。这清楚地表明，**仅靠少量有标签数据，模型无法充分学习到足以泛化到新数据的有效模式**。

# 5
在这个关键步骤中，我们构建并评估了“增强的自监督网络”。对于每个网络规模，其过程如下：
1. **特征提取**：我们使用一个预训练好的自编码器，并利用其编码器部分将原始的有标签训练数据和测试数据转换为一个新的、压缩的特征表示。这些新特征是从大量有标签和无标签数据中学习到的抽象概念。
2. **特征增强**：然后，我们将这些新学习到的特征与原始的像素特征进行拼接。这创建了“增强”的数据集，其中每个样本都由其原始像素和自编码器学习到的高级特征共同描述。
3. **分类器训练**：最后，我们在这个更丰富的、增强的训练数据上训练了一个新的3层神经网络分类器，并在增强的测试数据上评估了其性能。 我们现已将这些增强模型的测试误差存储在 `augmented_test_errors` 列表中。这完成了第六部分最终分析所需的全部计算，届时我们将把这些结果与我们的基准进行可视化比较。
# 6
1. **基准模型的局限性：** 基准分类器**仅在50个有标签的样本上进行训练**。这是一个非常小的数据集。由于数据如此之少，模型很难学习到能够代表潜在类别的、稳健且可泛化的特征。它极易对这个小训练集的特有“怪癖”产生过拟合，因此在未见过的测试数据上表现不佳，导致了较高的错误率。
    
2. **增强模型的优势：** 增强模型的优越性来自于**自编码器生成的额外特征**。其关键在于，自编码器是在一个大得多的数据集上训练的：即50个有标签样本**加上1500个无标签样本**。
    
    - **从未标记数据中学习：** 通过尝试重建1550张图像，自编码器被迫学习了整个数据分布中潜在的基础结构和常见模式（例如，构成数字“2”的曲线是怎样的，数字“8”的圆环是怎样的等等）。它在不需要任何标签的情况下，学习到了数据本质特征的、丰富的低维表示。
        
    - **为分类器提供更丰富的输入：** 当我们将这些预先学习到的、高质量的特征附加在原始像素数据之后，一同提供给最终的分类器时，我们给了它一个巨大的领先优势。分类器不再需要仅从50个样本中从零开始学习一切。它不仅接收原始数据，还接收到了一组有意义的、已经很擅长描述数据的抽象特征。这种更丰富、信息量更大的输入使得分类器能够学习到一个更有效、更具泛化能力的决策边界，从而显著降低了测试误差。
        

总而言之，增强网络的性能之所以优于基准网络，是因为它成功地**利用了大量的无标签数据**来学习一个更好的特征表示，这反过来又提升了最终监督分类器的性能，尤其是在有标签数据稀缺的情况下。
