### **第一部分：模型复杂度和模型选择 (共46分)**

这部分的目标是让您亲手实现机器学习中的两个核心组件——模型（KNN回归器）和评估方法（交叉验证），并用它们来分析模型复杂度（由参数K控制）如何影响模型性能。

#### **问题1：KNN回归器 (12分)**

- 
- **任务 I (实现 KnnRegressor 类):**
  - 
  - **目标:** 您需要创建一个名为 KnnRegressor 的Python类。这个类要能像 scikit-learn 里的模型一样工作，所以它需要继承 BaseEstimator 并包含 __init__, fit, predict 这三个标准方法。
  - __init__(self, k=...): 这是构造函数。它应该接收模型的超参数，最重要的就是邻居数量 k。您需要在这里把 k 存为类的属性，例如 self.k = k。
  - fit(self, x, y): 这个方法用来“训练”模型。对于KNN来说，训练过程非常简单，就是**把所有的训练数据 x 和它们对应的标签 y 储存起来**。例如，self.X_train_ = x 和 self.y_train_ = y。
  - predict(self, x_test): 这是最核心的方法。对于给定的测试数据集 x_test 里的每一个点，您需要：
    1. 
    2. 计算这个测试点与 fit 方法中存储的所有训练数据点 (self.X_train_) 之间的距离（通常是欧氏距离）。
    3. 找到距离最近的 k 个训练点（即K个近邻）。
    4. **回归 (Regression)** 的关键在于：预测值是这 k 个邻居的 **y 值的平均数**。这与分类（Classifier）不同，分类是取票数最多的类别。
  - **限制:** **绝对不能**直接 import 或使用 sklearn.neighbors.KNeighborsRegressor。您必须自己实现计算距离、寻找邻居和求平均值的逻辑。
- **任务 II (测试实现):**
  - 
  - **目标:** 验证您写的 KnnRegressor 是否能正常工作。
  - **步骤:**
    1. 
    2. 加载 sklearn.datasets.load_diabetes 数据集。
    3. 将数据分割成训练集（70%）和测试集（30%）。
    4. 选择一个固定的 k 值（例如，k=5）。
    5. 用您的 KnnRegressor 在训练集上调用 .fit()。
    6. 分别在训练集和测试集上调用 .predict()，得到预测结果。
    7. 计算并报告训练误差和测试误差。对于回归问题，通常使用**均方误差 (Mean Squared Error, MSE)** 作为误差度量。

------



#### **问题2：L-折交叉验证 (18分)**

- 
- **任务 I (实现 LFold 类):**
  - 
  - **目标:** 实现一个交叉验证的数据分割器。它不关心模型，只负责把数据集的索引分成 L 份，轮流作为训练集和测试集。
  - __init__(self, n_splits=...): 构造函数，接收折数 L (在代码中是 n_splits)。
  - get_n_splits(...): 一个简单的方法，直接返回折数 L。
  - split(self, x, ...): 核心方法。它应该是一个**生成器 (generator)**。当在一个循环中调用它时（如 for train_idx, test_idx in LFold(5).split(data):），它每次会 yield 一对索引数组：train_idx (当前折的训练数据索引) 和 test_idx (当前折的测试数据索引)。您需要自己实现如何将总数据索引分割成 L 份，并轮流组合它们。
  - **限制:** **不能**使用 sklearn.model_selection.KFold。
- **任务 II (系统性测试KNN):**
  - 
  - **目标:** 使用您实现的 LFold 来系统地评估不同 K 值对您实现的 KnnRegressor 的影响。
  - **步骤:**
    1. 
    2. 设定一个 K 值的范围，例如 K from 1 to 30。
    3. 对于**每一个 K 值**：
       a. 初始化一个 LFold 对象（例如，L=5 或 L=10）。
       b. 使用 LFold 对整个 diabetes 数据集进行交叉验证。
       c. 在每一折（fold）中，用训练部分训练您的 KnnRegressor(k=K)，然后在训练部分和测试部分分别计算误差。
       d. 记录下每一折的训练误差和测试误差。
       e. 完成所有折后，计算这个 K 值对应的**平均训练误差**、**平均测试误差**，以及它们的**标准差**。
    4. 完成所有 K 值的评估后，找出哪个 K 值获得了**最低的平均测试误差**，并报告这个 K 值。
- **任务 III (绘图与分析):**
  - 
  - **目标:** 将实验结果可视化并进行解读。
  - **绘图:**
    - 
    - 横坐标为K值 (1 to 30)。
    - 纵坐标为均方误差。
    - 在一张图上绘制两条曲线：一条是平均训练误差随K变化的曲线，另一条是平均测试误差随K变化的曲线。
    - 为这两条曲线添加**误差棒 (error bars)**，代表95%置信区间，计算公式已在题目中给出 (m ± 1.96 * s / sqrt(L))。
  - **分析:**
    - 
    - **评论K的影响:** 观察图表，描述随着K的增大，训练误差和测试误差的变化趋势。
    - **识别过拟合/欠拟合:**
      - 
      - **过拟合 (Overfitting):** 通常发生在 K 很小的时候。表现为训练误差极低，但测试误差很高。模型过于复杂，学到了训练数据中的噪声。
      - **欠拟合 (Underfitting):** 通常发生在 K 很大的时候。表现为训练误差和测试误差都很高。模型过于简单，无法捕捉数据的基本规律。
    - **评论L的影响 (可选但建议):** 可以尝试用不同的 L 值（如L=3, L=10）重复实验，观察L值对误差曲线的平滑度和置信区间宽度的影响。

------



#### **问题3：自动模型选择 (16分)**

- 
- **任务 I (实现 KnnRegressorCV 类):**
  - 
  - **目标:** 创建一个“智能版”的KNN回归器，它能在训练时自动完成交叉验证并选出最优的超参数 K。
  - **__init__(self, ks=..., cv=...):** 构造函数接收一个 K 值的候选列表 ks (例如 range(1, 21)) 和一个交叉验证对象 cv (例如您自己实现的 LFold(5))。
  - **fit(self, x, y):** 这是这个类的灵魂所在。当调用 .fit() 时，它应该执行以下**内部流程**：
    1. 
    2. 对传入的训练数据 (x, y)，使用 cv 对象进行交叉验证。
    3. 对每一个候选的 k 值 (在 self.ks 列表里)，计算其在交叉验证中的平均性能（通常是平均测试误差）。
    4. 找到在交叉验证中表现最好的那个 k 值，记为 k_best。
    5. **将 k_best 存储起来**，例如 self.k_ = k_best。
    6. 最后，用这个找到的 k_best 在**全部**的输入训练数据 (x, y) 上重新训练一个最终的KNN模型。
  - **predict(self, x_test):** 这个方法直接使用在 fit 过程中最终确定下来的模型（即使用 self.k_ 作为邻居数）来进行预测。
- **任务 II (测试 KnnRegressorCV):**
  - 
  - **目标:** 评估这个能自动调参的模型的效果。这通常通过**嵌套交叉验证 (Nested Cross-Validation)** 来完成。
  - **方案 (如图1所示):**
    1. 
    2. **外层循环:** 对数据进行一次划分（例如，简单的训练/测试集划分，或使用一个外层的交叉验证）。这一层是用来**评估 KnnRegressorCV 这个模型的最终性能**的。
    3. **内层流程:** 在外层循环的每个训练集上，调用 KnnRegressorCV.fit()。此时，fit 方法内部会自动执行它自己的交叉验证（内层CV）来选择一个最佳的 K。
  - **报告与分析:**
    - 
    - 报告在每次外层循环中，内部CV选出的 k 值是什么。
    - 将这个自动选出的 k 值与在外层测试集上表现最好的 k 值进行比较。它们是否接近？
    - 评论内部交叉验证过程是否成功地帮助我们找到了一个接近最优的模型。分析可能影响其成功与否的因素（例如，数据量大小，L 值的选择等）。

------



### **第二部分：岭回归 (共26分)**

这部分考察您对线性模型和正则化的理论理解与编程实现能力。

#### **问题4：岭回归 (26分)**

- 
- **任务 I (数学推导):**
  - 
  - **目标:** 从岭回归的损失函数出发，推导出模型权重的求解方法。
  - **起点:** 损失函数 = 均方误差 + L2正则化项，即 E(w) = ||Xw - y||² + λ||w||²。
  - **过程:** 您需要计算这个损失函数 E(w) 关于权重向量 w 的**梯度 (gradient)**，即 ∇E(w)。
  - **终点 (二选一):**
    1. 
    2. **梯度下降法:** 给出随机梯度下降（SGD）的权重更新规则：w_new = w_old - learning_rate * ∇E(w)。
    3. **解析解:** 令梯度 ∇E(w) = 0，解出 w 的表达式，即岭回归的**正规方程解 (Normal Equation)**：w = (XᵀX + λI)⁻¹Xᵀy。
  - **要求:** 在Markdown单元格中给出清晰的推导步骤，建议使用LaTeX来书写数学公式。
- **任务 II (编程实现):**
  - 
  - **目标:** 将您推导出的公式或算法转化为一个可工作的Python类。
  - **要求:** 同样遵循 scikit-learn 风格，实现一个包含 __init__, fit, predict 方法的岭回归模型类。
  - **限制:** **不能**使用 sklearn.linear_model 中的任何现成模型。
- **任务 III (实验与分析):**
  - 
  - **目标:** 在一个已知函数关系的人造数据集上，直观地研究正则化强度 λ 对模型性能的影响。
  - **a. 建立模型管道:**
    - 
    - 首先使用 PolynomialFeatures (degree=5) 将一维的 x 转换成高维特征。这会人为地创造一个非常复杂的模型，使其容易过拟合。
    - 然后将这些高维特征输入到您实现的岭回归模型中。
  - **b. 进行重复实验:**
    - 
    - 这是一个关键步骤，目的是为了获得稳定的结果。
    - **外层循环:** 重复实验至少10次。
    - **内层循环:** 在每次外层循环开始时，**只生成一次**小规模的训练集（例如20个点）。然后，用这个固定的训练集，去训练对应**所有不同 λ 值**的模型。
    - **评估:** 在一个单独生成的、规模很大的测试集上评估所有这些模型的性能。
  - **c. 绘图与讨论:**
    - 
    - **绘图:** 横坐标是 log(λ)，纵坐标是 log(MSE)。绘制训练误差和测试误差的平均曲线。
    - **讨论:**
      - 
      - **λ 的影响:** 描述曲线的形状。通常测试误差曲线会呈现一个"U"形。
      - **过拟合:** 当 λ 非常小（接近0）时，模型接近普通的最小二乘回归，在复杂特征下会严重过拟合（训练误差低，测试误差高）。
      - **欠拟合:** 当 λ 非常大时，正则化项占据主导，模型权重被强烈地惩罚趋向于0，导致模型过于简单，无法拟合数据（训练和测试误差都高）。
      - **最佳λ:** "U"形曲线的谷底对应着一个在偏差（bias）和方差（variance）之间取得良好平衡的最佳 λ 值。

------



### **第三部分：逻辑回归 vs. 贝叶斯分类器 (共28分)**

这部分旨在通过实验对比判别模型（逻辑回归）和生成模型（贝叶斯分类器）在不同数据量下的行为和性能，考察您对这两类模型本质区别的理解。

#### **问题5：判别模型 vs. 生成模型 (28分)**

- 
- **任务 I (基线性能测试):**
  - 
  - **目标:** 在一个固定的数据集划分上，了解各个模型的初始表现。
  - **步骤:**
    1. 
    2. 加载 breast_cancer 数据集。
    3. 导入 LogisticRegression 和您在之前活动中实现的贝叶斯分类器代码。
    4. 考虑多种贝叶斯分类器：朴素贝叶斯（特征独立，无共享协方差）、带全协方差矩阵的贝叶斯等。
    5. 进行一次80/20的训练/测试集划分。
    6. 训练所有模型，并报告它们在训练集和测试集上的性能（例如，准确率）。
- **任务 II (学习曲线实验):**
  - 
  - **目标:** 设计一个实验，系统地研究训练数据量对模型性能的影响。
  - **步骤:**
    1. 
    2. 设定一个训练样本量 N 的序列，例如 N = 5, 10, 20, 50, 100, ..., 500。
    3. 对于**每一个 N 值**：
       a. **重复10次**实验来降低随机性。
       b. 在每次重复中，从完整数据集中**随机抽取 N 个样本**作为当前的训练集（确保 shuffle=True）。
       c. 用这个大小为 N 的训练集，去训练**所有**的模型（逻辑回归、各种贝叶斯分类器）。
       d. 在一个固定的、大的测试集上评估所有这些训练好的模型。
       e. 记录下所有模型的训练误差和测试误差。
    4. 实验结束后，对于每个 N 值和每个模型，您应该有10个训练误差和10个测试误差，可以计算它们的平均值。
- **任务 III (绘图):**
  - 
  - **目标:** 将学习曲线实验的结果可视化。
  - **要求:**
    - 
    - 横坐标是训练样本量 N。
    - 纵坐标是模型的性能指标（如准确率或错误率）。
    - 为**每个模型**绘制两条曲线：平均训练性能随 N 变化的曲线，和平均测试性能随 N 变化的曲线。
    - 将所有模型的曲线画在一张或几张图上以便于比较。
- **任务 IV (分析与回答):**
  - 
  - **目标:** 基于您的实验结果，进行深入的分析和总结。
  - **a. 性能变化趋势:** 随着训练数据点 N 的增加，每个分类器的训练性能和测试性能分别发生了什么变化？（通常，训练性能会略微下降或持平，测试性能会上升并趋于稳定，两者之间的差距会缩小）。
  - **b. 适用场景:** 当训练集很**小**时，哪个分类器表现最好？当训练集很**大**时，又是哪个？
  - **c. 解释与推测:**
    - 
    - **为什么？** 尝试解释您在b中的观察。这需要您思考模型的**根本差异**。
    - **提示:** 考虑**模型复杂度**和**模型假设**。
      - 
      - **生成模型 (如朴素贝叶斯):** 它们对数据的分布有很强的假设（例如，朴素贝叶斯假设特征之间条件独立）。这种强假设在数据很少时像一种“先验知识”，能防止过拟合，所以小样本时可能表现更好。但如果假设不成立，当数据量增多时，其性能会受限于这个错误的假设。
      - **判别模型 (如逻辑回归):** 它们直接学习决策边界，模型假设较弱，更灵活。在数据量少时，可能因为灵活性而过拟合。但当数据量充足时，它们能学习到更复杂的决策边界，从而超越假设过于简单的生成模型。
    - **参数数量:** 也可以从模型需要学习的参数数量来分析。参数少的模型（如朴素贝叶斯）需要的数据量也少。参数多的模型需要更多数据才能被充分训练