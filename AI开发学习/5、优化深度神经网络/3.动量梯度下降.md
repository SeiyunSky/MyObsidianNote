梯度下降有一个问题，当某一参数有局部最优解时，也就是loss对这个参数的偏导数在某一个很小的局部接近0。这时，传统的梯度下降算法对这个参数的更新就非常慢，停滞不前。

### 动量梯度下降
动量梯度下降的做法是每次不用当前每个参数的梯度值来更新参数，而是用梯度值的**指数加权平均**来更新参数。

### 动量梯度的更新过程
以对w参数的更新为例，首先计算w的梯度：
$$g_w =\frac {∂loss}{∂w}$$
定义变量$V_w$表示梯度的指数加权平均值
$$V_w = βV_w + (1 - β)g_w$$
更新梯度
$$w = w - lrV_w$$

