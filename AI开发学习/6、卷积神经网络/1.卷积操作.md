### 卷积运算过程
![[Pasted image 20251017134044.png]]
**输入**：将其拆解为 n * n * 1 的张量，最后的维度为1表示只有一个灰度值通道。
**参数** ： 获得应该卷积核，和偏置b，共同称为过滤器

在进行卷积运算时，卷积核从图像的左上角开始，从上到下，从左到右，进行扫描。每次对3x3的像素进行卷积运算。卷积运算对每个位置的像素值和卷积核对应位置的权重相乘，然后累加，最后再加上偏置b，得到z值，然后z值经过激活函数后，得到a值。a值为新的“图片”上的一个“像素”。新的“图片”，我们称为特征图，特征图上的每个“像素”都是从原始图片上提取的一个特征。比如在检测猫的任务中，一个a值可能代表是否在这个卷积区域发现了猫的眼睛。
![[Pasted image 20251017134247.png]]
重复多次后就能够降低参数量，并利用到平移不变性和特征的局部性。

**卷积操作可以看作有先验知识的参数共享的全连接层**
![[Pasted image 20251017134741.png]]
**对于多通道情况需要对多层进行卷积操作，输出通道数还是1个**
**对于多卷积操作**，**输出通道数就需要进行增加**，每一层都能够作为是一个特征提取器


### 感受野
![[Pasted image 20251017140537.png]]
如果原始图片的尺寸为6x6，那么做完第一次3x3的卷积后，生成的特征图为4x4，在这4x4的特征图里，每个特征都是由原始图片里3x3的像素参与运算得到。所以我们说第一次卷积操作生成的特征图每个特征的感受野是3x3。
在第一次卷积生成的特征图上我们继续做第二次卷积，得到的特征图大小为2x2，在这个2x2的特征图里，每个特征都是由原始图片里5x5的像素参与运算得到的。所以我们说第二次卷积操作生成的特征图每个特征的感受野是5x5。
感受野是指当前特征图里的每个特征是由原始多大区域的像素参与运算得到的。
我们通过观察可以看到，随着卷积的不断进行，生成的特征图越来越小，但是特征图的感受野越来越大。这刚好也契合了深度神经网络的特性，浅层网络发现细节局部的特征，深层网络发现更加宏观整体的特征。

### 卷积核的大小

### 步长

### Padding
![[Pasted image 20251017140904.png]]
在周围添加一圈全0的像素，用来均匀化特征
