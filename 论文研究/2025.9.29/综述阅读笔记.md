## **Byzantin Stochastic Gradient Descent——维护历史梯度和**
研究拜占庭设置下的随机优化问题，存在一个未知分布，目标是最小化$$f(x) =^{def} E_{s-D}[f_s(x)]$$
光滑，凸，且知道拜占庭比例小于50%
![[Pasted image 20250923190939.png]]
存在一定比例的情况下， 可以知道满足x的点满足：
![[Pasted image 20250923191012.png|300]]
核心目的是**找到全局最小点**
假设条件为 **梯度有界**
#### 提出的算法
输入学习率，初始模型，D为约束参数，T为迭代轮次，和两个可信值
**Amed**存储梯度与参数方向的内积累计和，检查梯度**方向**与整体更新方向的一致性
**Bmen**历史梯度的累计和，检查梯度**大小**长期来看是否合理

根据**长期一致性**、**长期大小大小合理性**和**短期合理性（梯度方差）** 决定是否更新该节点供给的值。
**核心问题在于——
    维护历史信息的高计算开销与存在不支持异步的问题**
    **理论阈值依赖于的常熟在一般情况下未知**
    **无法解决触发器注入式的攻击**
![[Pasted image 20250923191919.png|650]]

## SafeGuardSGD
算法复杂度：
![[Pasted image 20250923201411.png]]
核心是在处理非凸情况下给出了一个算法，
假设包括**L光滑性和L2光滑性**
目标是**找到一个本地最值满足**
$$||\nabla f(x)\leq \epsilon|| \ \ \ \ and \ \ \ \ \nabla^2f(x) \geq - \sqrt{\epsilon}I$$
**二阶临界点本质上是局部最小点，但是我们相信驻点本身大部分情况下就是最好的点。**
#### 核心算法
**算法一** ——**带双重安全保护的扰动SGD**
核心在于
T0是一个短期窗口，用于单次迭代中拦截明显异常
T1为长期窗口，用于识别缓慢渗透的恶意节点
![[Pasted image 20250923203620.png|300]]
算法模型更新公式：![[Pasted image 20250923203748.png]]
通过注入高斯噪声逃离鞍点、通过长短期序列的一致性，在梯度序列独立、零均值的情况下，就能够依据概率获得收敛的累计和。
![[Pasted image 20250923202141.png]]
**算法二** ——只采用一个安全措施
这里的核心过滤规则是计算Bi向量的鲁棒中位数
如果中位数向量存在至少一般的节点满足在可行度内，就作为中位数使用。
![[Pasted image 20250923202202.png]]

## ASKEL——集中式的梯度聚合
![[Pasted image 20250923214231.png]]