**聚合方式**
![[Pasted image 20251011162134.png]]

**提出背景**：
线性方式的失效
![[Pasted image 20251011162635.png]]

![[Pasted image 20251011162432.png]]

**算法逻辑**
![[Pasted image 20251011162751.png]]
找到每个节点最近的邻居，
邻居间根据彼此之间的距离评分，
得到分数最符合需求的n−f−2个最近邻向量个worker
选择对应分数最符合的n−f−2个最近邻向量个worker进行聚合。

**收敛性分析**
![[Pasted image 20251011162931.png]]
其中至少有n-f个向量是正确的

对于一个正确的索引i
![[Pasted image 20251011163013.png|100]]
，有局部标准差![[Pasted image 20251011163005.png]]

**对于时间复杂度有：**
![[Pasted image 20251011163314.png]]

**对于拜占庭弹性有**：
这里有两个大前提 
- **2f + 2 < n**
- **η(n, f) ⋅ √d ⋅ σ < ||g||**
![[Pasted image 20251011172200.png]]
![[Pasted image 20251011164832.png]]
![[Pasted image 20251011165204.png]]
定义：
![[Pasted image 20251011164908.png]]$\eta(n, f) \overset{\text{def}}{=} \sqrt{\frac{2(n-f+f\cdot(n-f-2)+f^2\cdot(n-f-1))}{n-2f-2}}$
首先——推导诚实向量分数的最大期望：
![[Pasted image 20251011165307.png]]
![[Pasted image 20251011165508.png]]
对于这种初步上界，考虑到拜占庭节点并非简单远离，而是会采用更优的策略——靠近诚实节点以冒充其，命题中的学习率分子来源于更紧的上界。
![[Pasted image 20251011165720.png]]

**下一步是求误差下界**
![[Pasted image 20251011165809.png]]
对于任意一个诚实邻居，使用**柯西——施瓦茨不等式**
![[Pasted image 20251011165852.png]]
得到最终输出到g的距离可以被其到诚实邻居与诚实邻居到g的距离约束。而对于所有的诚实邻居，累加后可以得到
$$\sum_{k \in C'} \|V_{i^*} - g\|^2 = |C'| \cdot \|V_{i^*} - g\|^2$$
$$\sum_{k \in C'} \left( 2\|V_{i^*} - V_k\|^2 + 2\|V_k - g\|^2 \right) = 2 \sum_{k \in C'} \|V_{i^*} - V_k\|^2 + 2 \sum_{k \in C'} \|V_k - g\|^2$$
其中，$2 \sum_{k \in C'} \|V_{i^*} - V_k\|^2$只是$score(i*)$的子集，因此有
![[Pasted image 20251011170751.png|400]]
![[Pasted image 20251011170829.png|300]]

对其取期望，得到多次krum的上界，因为C‘是随机变量，代表了诚实节点的数量，因此取n-2f-2这个下界

使用krum分数小于等于score(j)（被选中的小于等于其他任意的点），可以得到![[Pasted image 20251011171226.png]]
根据论文内的数学方法可以看到最后一项能被第一项吸收，因此利用原来的E\[score(j)]的上界，可以得到
![[Pasted image 20251011171608.png]]
最终根据**詹森不等式**$E[X^2]≥(E[X])^2$
有
![[Pasted image 20251011171721.png]]
说明——krum输出的期望向量，必然落在以g为球心，半径为r的高维球体内部
也就是说，在最坏的情况下
$\sin(\text{角}) = \frac{\text{对边}}{\text{斜边}}$其中边长分别为斜边∥g∥、∥E\[KR]∥、和 对边∥E\[KR]−g∥
![[Pasted image 20251011171813.png]]
$$\sin \alpha \overset{\text{def}}{=} \frac{r}{|g|} = \frac{\eta(n, f) \cdot \sqrt{d} \cdot \sigma}{|g|}$$


**对于SGD收敛性**
