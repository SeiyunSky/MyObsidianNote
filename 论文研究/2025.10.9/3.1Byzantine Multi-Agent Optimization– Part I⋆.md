【介绍其收敛性失效原因，反证法】
![[Pasted image 20251003145808.png|200]]
定理一：当存在拜占庭节点时，该方法是无解的
![[Pasted image 20251003150029.png]]

![[Pasted image 20251003145705.png]]
![[Pasted image 20251003145712.png]]

安全边界是 `n > 2f`，而通常表述为 `n ≥ 3f + 1`

【基础松弛情况下的目标函数】
$$x^* \in \arg\min_{x} \frac{1}{|N|} \sum_{i \in N} h_i(x)$$
对各个节点进行权重的归一化和非负约束
然而没有保证多数智能体的权重有效性，因此需要进一步约束

【进一步约束】
对于上式，至少保证至少$\gamma$个$(\alpha_i>\beta)$
定理二：选取的$\gamma$含有天然上限
![[Pasted image 20251003211156.png]]
那么结合$\gamma$和$\alpha_i$这两个核心——排除在外和均值化就能得到拜占庭情况下联邦学习的两个基本方向。