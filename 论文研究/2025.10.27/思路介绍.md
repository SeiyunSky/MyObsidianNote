### 一、明确问题特点
首先，我们知道，在联邦学习背景下，分为中心化与去中心化两个基本架构
对于中心化，即有中心服务器的联邦学习任务
![[Pasted image 20251030222234.png]]
我们的核心优化目标是
$$w^* = argmin_wF(w)$$
其中有$$F(w) = E_{DX}[f(D,w)]$$
含义是在联合训练数据集上的经验损失f(D,w)的期望，另外
$$f(w) = \sum_{k=1}^{K} \frac{n_{k}}{n} F_{k}(w)
\quad\text{where}\quad$$
$$F_{k}(w) = \frac{1}{n_{k}} \sum_{i \in \mathcal{P}_{k}} f_{i}(w)$$
当遭遇拜占庭攻击或类似故障时，基于良性节点数据及训练结果最终能够收敛的前提，能得到如下的优化目标
$$x^* \in \arg\min_{x} \frac{1}{|N|} \sum_{i \in N} h_i(x)$$
在有中心服务器的情况下，容易得到的结论有——
- 对于聚合筛选过程，我们有所有子节点的更新情况
- 对于下一步更新，已完成的上一步更新是在算法框架内视为绝对可信的过程。


基于上述两个结论，我们在**过滤筛选**这一层角度上，进而衍生出的防御哲学有——离群筛选、权威仲裁。

#### 1.1 **基础方法**
**离群筛选的开创性方法——Krum**
**参考文献**：**Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent**
![[Pasted image 20251031145639.png]]
  ![[Pasted image 20251031145706.png]]

**权威仲裁的核心方法——FLTrust**
**参考文献**：**Fltrust:Byzantine-robust federated learning via trust bootstrapping**
![[Pasted image 20251025162614.png|350]]

在实际筛选过程中，过程如下：
![[Pasted image 20251025161150.png]]


**1.2 直接迁移到去中心化环境下存在的问题**
Note that FedAvg, Krum, Trimmed Mean (Trim mean), Median, and FLTrust were originally designed for server-assisted FL, which are adapted to the DFL setting.

首先考虑Krum——如此一来，被恶意节点包围的情况下将直接滑向恶意节点方

其次是FLTrust——IID、根数据集派发？

### 二、**去中心化下的优化目标和派生方法**
对于去中心化环境下，我们要注意其特点是——
- 各个节点之间能够直接进行信息交互的方式只有邻居
- 不再有任何一个良性节点能够获取到完整的全局信息
因此在核心优化目标上，从让最终模型趋近于”最优模型“，变成了
$$\min_{x \in \mathbb{R}^{d}} F(x) \quad \text{where} \quad F(x) := \frac{1}{n} \sum_{i=1}^{n} F_{i}(x)$$
$$min_{w_1, w_2, ..., w_N} \frac1N * Σ_{i=1}^N F_i(w_i)$$
以及
$$subject\  to\  w_i = w_j\ ,\  for\  all \ connected\  nodes \ (i, j)$$

- **核心矛盾**:
    - 性能目标，在Non-IID数据下，会驱动模型产生**“善意的分歧。
    - 共识目标，则要求必须通过聚合来抹平分歧。
- **引入攻击后的新挑战**:
    - 拜占庭攻击者，会向系统注入恶意的、错误的向心力”，试图将共识拉向一个错误的方向。

因此为了解决中心化方法的问题，适配这个”共识“，就有了如下的方法

#### **SCCLIP**
**参考文献**：**Byzantine-robust decentralized learning via self-centered clipping**

![[Pasted image 20250909201655.png|300]]

#### **Balance**
![[Pasted image 20250909110045.png]]
![[Pasted image 20250909110147.png]]
Balance是如何解决如下问题的？
- 数据异构性挑战
- 证明“动态系统”的整体行为收敛
- 信任孤岛问题

#### **DFL-DUAL**
引入多维度验证
**参考文献**：**Byzantine-robust Decentralized Federated Learning via Dual-domain Clustering and Trust Bootstrapping**
1. **模型域证据**: 欧氏距离 $$d_euc(i, j) = |w_i - w_j|²$$
    
2. **数据域证据**: 数据签名间的距离 $$ d_{data}(i, j) = ||D_{isig} - D_{jsig}||² $$(实际论文采用了更深度的方法，没去细看)


### 三、**当前方法存在的问题**

**Krum** → **DFL-DUAL**
  机制的复杂性与可解释性差
  隐私泄露风险

**FlTrust** → **Balance** 
  隐私泄露风险
  硬过滤问题  


### 四、**可能的解决方案**

FLTrust的核心思想上，实际上体现出了一种可能性——$weight_j = ReLU(cos(w_i, w_j))$
![[Pasted image 20251025161150.png]]


#### **核心算法：自锚定幅度对齐软加权聚合 **

**输入**:
- 节点i自身的本地更新后模型: $w_i'$
- 所有邻居的本地更新后模型集合: ${w_j' | j ∈ N_i}$
- 自身在最终聚合中的信任权重: $α ∈ [0, 1]$
**输出**:
- 节点i在本轮更新后的最终模型: $w_i^{(t+1)}$
---
##### **第一部分：过滤**
**Step 1: 计算邻居权重**
对于每一个邻居 $j ∈ N_i$，计算其信任权重 $φ_j$：

$$
ϕ_j=ReLU(\frac {⟨w_i^′,w_j^′⟩}{∣∣w_i^′∣∣⋅∣∣w_j^′∣∣})
$$

---

##### 第二部分：聚合 
聚合过程包含两个关键步骤：**幅度对齐**和**加权平均**

**Step 2: 幅度对齐**
对于每一个**权重不为零**的邻居 j (即 φ_j > 0)，计算其对齐后的模型 $w̃_j'$：

$$
w̃_j'=∣∣w_i^′∣∣⋅\frac{w_j^′}{∣∣w_j^′∣∣}
$$


**Step 3: 最终加权聚合**
计算所有有效邻居（φ_j > 0）的对齐后模型的加权平均值 $AGG_i$：

$$AGG_i​=\frac{​∑_{j∈N_i}​​ϕ_j​⋅w̃_j^′}{∑_{k∈N_i}​​ϕ_k + \theta}$$
**Step 4: 结合自身模型 (Self-Model Integration)**

计算本轮的最终模型 $w_i^{(t+1)}$：

$$
w_i^{(t+1)}=α⋅w_i^′+(1−α)⋅AGG_i​
$$


结合Balance来看，我们可能遇到的问题似乎有了一定程度的解决方案
- **如何解决动态权重导致的不一致问题**——数学方法上利用余弦相似度在Relu下有界的特性，考虑利用均值期望来圈定动态权重的影响

- **网络拓扑产生何种影响**——转化为整体+个体的问题

- **当数据同质性低时**，**在权重不一致的情况下如何实现一致共识**——将一致共识的证明思路（证明收敛到误差球中）转化为**模型本身是否能集体收敛进球** $$E[||w_{avg}^{(t+1)} - w^*||²]$$
	在上式基础上，引入其Non-IID产生的影响——也可以考虑用期望的方法去简化

- **过滤与结合**——Relu的特性是负数取0，对偏差过大的进行了去除，而当存在可控范围内的数据差异时，软加权能够让此类邻居发挥作用。

- **信任孤岛问题**——Balance通过引入时变量，是否能在软加权基础上引入时变量？



