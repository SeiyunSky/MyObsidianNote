### 一、明确问题特点
首先，我们知道，在联邦学习背景下，分为中心化与去中心化两个基本架构
对于中心化，即有中心服务器的联邦学习任务
![[Pasted image 20251030222234.png]]
我们的核心优化目标是
$$w^* = argmin_wF(w)$$
其中有$$F(w) = E_{DX}[f(D,w)]$$
含义是在联合训练数据集上的经验损失f(D,w)的期望，另外
$$f(w) = \sum_{k=1}^{K} \frac{n_{k}}{n} F_{k}(w)
\quad\text{where}\quad$$
$$F_{k}(w) = \frac{1}{n_{k}} \sum_{i \in \mathcal{P}_{k}} f_{i}(w)$$
当遭遇拜占庭攻击或类似故障时，基于良性节点数据及训练结果最终能够收敛的前提，能得到如下的优化目标
$$x^* \in \arg\min_{x} \frac{1}{|N|} \sum_{i \in N} h_i(x)$$
![[Pasted image 20251030222234.png]]
在有中心服务器的情况下，容易得到的结论有——
- 对于聚合筛选过程，我们有所有子节点的更新情况
- 对于下一步更新，已完成的上一步更新是在算法框架内视为绝对可信的过程。


基于上述两个结论，我们在过滤这一层角度上，进而衍生出的防御哲学有——离群筛选、权威仲裁。







